#!/bin/bash
set -euo pipefail

# –°–∫—Ä–∏–ø—Ç –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è persistent volumes AquaStream
# –°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—ã–µ –∫–æ–ø–∏–∏ PostgreSQL, Elasticsearch, –∏ –¥—Ä—É–≥–∏—Ö –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "${SCRIPT_DIR}/../.." && pwd)"

# –¶–≤–µ—Ç–∞ –¥–ª—è –≤—ã–≤–æ–¥–∞
NC="\033[0m"; GREEN="\033[0;32m"; YELLOW="\033[0;33m"; RED="\033[0;31m"; BLUE="\033[0;34m"

log() {
    local level="$1"; shift
    local msg="$*"
    local color="$GREEN"
    case "$level" in
      INFO)  color="$GREEN";;
      WARN)  color="$YELLOW";;
      ERROR) color="$RED";;
      DEBUG) color="$BLUE";;
    esac
    echo -e "[$(date '+%Y-%m-%d %H:%M:%S')] ${color}${level}${NC} ${msg}"
}

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
BACKUP_DIR="${BACKUP_DIR:-${PROJECT_ROOT}/backups}"
BACKUP_DATE="$(date +%Y%m%d_%H%M%S)"
RETENTION_DAYS="${RETENTION_DAYS:-30}"
COMPOSE_FILE="${PROJECT_ROOT}/infra/docker/compose/docker-compose.yml"

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –±—ç–∫–∞–ø–æ–≤
mkdir -p "$BACKUP_DIR"

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
if [ -f "${PROJECT_ROOT}/infra/docker/compose/.env" ]; then
    source "${PROJECT_ROOT}/infra/docker/compose/.env"
else
    log ERROR "–§–∞–π–ª .env –Ω–µ –Ω–∞–π–¥–µ–Ω!"
    exit 1
fi

# –§—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–æ–≤
check_service_health() {
    local service_name="$1"
    local max_attempts=10
    local attempt=1
    
    log INFO "–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞ $service_name..."
    
    while [ $attempt -le $max_attempts ]; do
        if docker compose -f "$COMPOSE_FILE" ps "$service_name" | grep -q "healthy\|Up"; then
            log INFO "‚úÖ –°–µ—Ä–≤–∏—Å $service_name –≥–æ—Ç–æ–≤"
            return 0
        fi
        
        log WARN "–°–µ—Ä–≤–∏—Å $service_name –Ω–µ –≥–æ—Ç–æ–≤ (–ø–æ–ø—ã—Ç–∫–∞ $attempt/$max_attempts)"
        sleep 5
        attempt=$((attempt + 1))
    done
    
    log ERROR "‚ùå –°–µ—Ä–≤–∏—Å $service_name –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ—Å–ª–µ $max_attempts –ø–æ–ø—ã—Ç–æ–∫"
    return 1
}

# –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ PostgreSQL
backup_postgresql() {
    log INFO "=== –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ PostgreSQL ==="
    
    local backup_file="${BACKUP_DIR}/postgres_backup_${BACKUP_DATE}.sql.gz"
    
    if ! check_service_health "postgres"; then
        log ERROR "PostgreSQL –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –±—ç–∫–∞–ø"
        return 1
    fi
    
    log INFO "–°–æ–∑–¥–∞–Ω–∏–µ SQL –¥–∞–º–ø–∞ PostgreSQL..."
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –¥–∞–º–ø –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    docker compose -f "$COMPOSE_FILE" exec -T postgres pg_dumpall -U postgres | gzip > "$backup_file"
    
    if [ -f "$backup_file" ] && [ -s "$backup_file" ]; then
        local size=$(du -h "$backup_file" | cut -f1)
        log INFO "‚úÖ PostgreSQL –±—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: $backup_file (—Ä–∞–∑–º–µ—Ä: $size)"
        
        # –°–æ–∑–¥–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –¥–∞–º–ø —Ç–æ–ª—å–∫–æ —Å—Ö–µ–º—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        local schema_file="${BACKUP_DIR}/postgres_schema_${BACKUP_DATE}.sql"
        docker compose -f "$COMPOSE_FILE" exec -T postgres pg_dumpall -U postgres --schema-only > "$schema_file"
        log INFO "‚úÖ –°—Ö–µ–º–∞ PostgreSQL —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: $schema_file"
        
        return 0
    else
        log ERROR "‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è PostgreSQL –±—ç–∫–∞–ø–∞"
        return 1
    fi
}

# –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ Elasticsearch
backup_elasticsearch() {
    log INFO "=== –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ Elasticsearch ==="
    
    if ! check_service_health "elasticsearch"; then
        log ERROR "Elasticsearch –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –±—ç–∫–∞–ø"
        return 1
    fi
    
    local es_backup_dir="${BACKUP_DIR}/elasticsearch_${BACKUP_DATE}"
    mkdir -p "$es_backup_dir"
    
    # –°–æ–∑–¥–∞–µ–º snapshot —á–µ—Ä–µ–∑ Elasticsearch API
    log INFO "–°–æ–∑–¥–∞–Ω–∏–µ —Å–Ω–∏–º–∫–∞ Elasticsearch –¥–∞–Ω–Ω—ã—Ö..."
    
    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º snapshot repository
    local repo_response
    repo_response=$(docker compose -f "$COMPOSE_FILE" exec -T elasticsearch curl -s -k \
        --cacert config/certs/ca/ca.crt \
        -u "elastic:${ELASTIC_PASSWORD}" \
        -X PUT "https://localhost:9200/_snapshot/backup_repo" \
        -H "Content-Type: application/json" \
        -d "{
            \"type\": \"fs\",
            \"settings\": {
                \"location\": \"/usr/share/elasticsearch/backup\",
                \"compress\": true
            }
        }")
    
    if echo "$repo_response" | grep -q '"acknowledged":true'; then
        log INFO "‚úÖ Snapshot repository –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω"
    else
        log WARN "‚ö†Ô∏è Repository —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: $repo_response"
    fi
    
    # –°–æ–∑–¥–∞–µ–º snapshot –≤—Å–µ—Ö –∏–Ω–¥–µ–∫—Å–æ–≤
    local snapshot_name="snapshot_${BACKUP_DATE}"
    local snapshot_response
    snapshot_response=$(docker compose -f "$COMPOSE_FILE" exec -T elasticsearch curl -s -k \
        --cacert config/certs/ca/ca.crt \
        -u "elastic:${ELASTIC_PASSWORD}" \
        -X PUT "https://localhost:9200/_snapshot/backup_repo/${snapshot_name}" \
        -H "Content-Type: application/json" \
        -d "{
            \"indices\": \"aquastream-*\",
            \"ignore_unavailable\": true,
            \"include_global_state\": false,
            \"metadata\": {
                \"taken_by\": \"backup-script\",
                \"taken_because\": \"scheduled backup\"
            }
        }")
    
    # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è snapshot
    log INFO "–û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è snapshot..."
    local max_wait=300  # 5 –º–∏–Ω—É—Ç
    local elapsed=0
    
    while [ $elapsed -lt $max_wait ]; do
        local status_response
        status_response=$(docker compose -f "$COMPOSE_FILE" exec -T elasticsearch curl -s -k \
            --cacert config/certs/ca/ca.crt \
            -u "elastic:${ELASTIC_PASSWORD}" \
            "https://localhost:9200/_snapshot/backup_repo/${snapshot_name}")
        
        if echo "$status_response" | grep -q '"state":"SUCCESS"'; then
            log INFO "‚úÖ Elasticsearch snapshot —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ"
            
            # –ö–æ–ø–∏—Ä—É–µ–º snapshot –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            docker cp "$(docker compose -f "$COMPOSE_FILE" ps -q elasticsearch):/usr/share/elasticsearch/backup/." "$es_backup_dir/"
            
            if [ -d "$es_backup_dir" ] && [ "$(ls -A "$es_backup_dir")" ]; then
                local size=$(du -sh "$es_backup_dir" | cut -f1)
                log INFO "‚úÖ Elasticsearch –¥–∞–Ω–Ω—ã–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã: $es_backup_dir (—Ä–∞–∑–º–µ—Ä: $size)"
                return 0
            else
                log ERROR "‚ùå –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è Elasticsearch –¥–∞–Ω–Ω—ã—Ö"
                return 1
            fi
        elif echo "$status_response" | grep -q '"state":"FAILED"'; then
            log ERROR "‚ùå Elasticsearch snapshot –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: $status_response"
            return 1
        fi
        
        sleep 10
        elapsed=$((elapsed + 10))
    done
    
    log ERROR "‚ùå Timeout –æ–∂–∏–¥–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è Elasticsearch snapshot"
    return 1
}

# –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
backup_configs() {
    log INFO "=== –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π ==="
    
    local config_backup_dir="${BACKUP_DIR}/configs_${BACKUP_DATE}"
    mkdir -p "$config_backup_dir"
    
    # –ö–æ–ø–∏—Ä—É–µ–º –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    local configs=(
        "${PROJECT_ROOT}/infra/docker/compose/docker-compose.yml"
        "${PROJECT_ROOT}/infra/docker/compose/.env"
        "${PROJECT_ROOT}/infra/monitoring"
        "${PROJECT_ROOT}/infra/scripts"
        "${PROJECT_ROOT}/run.sh"
    )
    
    for config in "${configs[@]}"; do
        if [ -e "$config" ]; then
            cp -r "$config" "$config_backup_dir/"
            log INFO "‚úÖ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω: $(basename "$config")"
        else
            log WARN "‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω: $config"
        fi
    done
    
    # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
    local config_archive="${BACKUP_DIR}/configs_${BACKUP_DATE}.tar.gz"
    tar -czf "$config_archive" -C "$config_backup_dir" .
    rm -rf "$config_backup_dir"
    
    local size=$(du -h "$config_archive" | cut -f1)
    log INFO "‚úÖ –ê—Ä—Ö–∏–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π —Å–æ–∑–¥–∞–Ω: $config_archive (—Ä–∞–∑–º–µ—Ä: $size)"
}

# –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ Docker volumes
backup_docker_volumes() {
    log INFO "=== –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ Docker volumes ==="
    
    local volumes_backup_dir="${BACKUP_DIR}/volumes_${BACKUP_DATE}"
    mkdir -p "$volumes_backup_dir"
    
    # –°–ø–∏—Å–æ–∫ –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö volumes
    local volumes=(
        "postgres_data"
        "elasticsearch_data"
        "elasticsearch_certs"
        "zookeeper_data"
        "kafka_data"
        "nginx_logs"
    )
    
    for volume in "${volumes[@]}"; do
        local volume_full_name="aquastream_${volume}"
        
        if docker volume ls | grep -q "$volume_full_name"; then
            log INFO "–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ volume: $volume"
            
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö volume
            local archive_name="${volumes_backup_dir}/${volume}.tar.gz"
            docker run --rm \
                -v "${volume_full_name}:/volume:ro" \
                -v "${volumes_backup_dir}:/backup" \
                alpine:latest \
                tar -czf "/backup/${volume}.tar.gz" -C /volume .
            
            if [ -f "$archive_name" ] && [ -s "$archive_name" ]; then
                local size=$(du -h "$archive_name" | cut -f1)
                log INFO "‚úÖ Volume $volume –∑–∞–∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω: $archive_name (—Ä–∞–∑–º–µ—Ä: $size)"
            else
                log WARN "‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞—Ä—Ö–∏–≤–∏—Ä–æ–≤–∞–Ω–∏—è volume: $volume"
            fi
        else
            log WARN "‚ö†Ô∏è Volume –Ω–µ –Ω–∞–π–¥–µ–Ω: $volume_full_name"
        fi
    done
}

# –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤
cleanup_old_backups() {
    log INFO "=== –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤ (—Å—Ç–∞—Ä—à–µ $RETENTION_DAYS –¥–Ω–µ–π) ==="
    
    local deleted_count=0
    
    # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª—ã —Å—Ç–∞—Ä—à–µ RETENTION_DAYS –¥–Ω–µ–π
    while IFS= read -r -d '' file; do
        rm "$file"
        deleted_count=$((deleted_count + 1))
        log INFO "üóëÔ∏è –£–¥–∞–ª–µ–Ω —Å—Ç–∞—Ä—ã–π –±—ç–∫–∞–ø: $(basename "$file")"
    done < <(find "$BACKUP_DIR" -type f -mtime +$RETENTION_DAYS -print0 2>/dev/null || true)
    
    # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    find "$BACKUP_DIR" -type d -empty -delete 2>/dev/null || true
    
    if [ $deleted_count -gt 0 ]; then
        log INFO "‚úÖ –£–¥–∞–ª–µ–Ω–æ —Å—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤: $deleted_count"
    else
        log INFO "‚ÑπÔ∏è –°—Ç–∞—Ä—ã—Ö –±—ç–∫–∞–ø–æ–≤ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
    fi
}

# –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –±—ç–∫–∞–ø–µ
create_backup_report() {
    log INFO "=== –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –±—ç–∫–∞–ø–µ ==="
    
    local report_file="${BACKUP_DIR}/backup_report_${BACKUP_DATE}.txt"
    
    cat > "$report_file" << EOF
AquaStream Backup Report
=======================
–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è: $(date)
–í–µ—Ä—Å–∏—è —Å–∫—Ä–∏–ø—Ç–∞: 1.0
Retention –ø–µ—Ä–∏–æ–¥: $RETENTION_DAYS –¥–Ω–µ–π

–°–¢–ê–¢–£–° –†–ï–ó–ï–†–í–ù–û–ì–û –ö–û–ü–ò–†–û–í–ê–ù–ò–Ø:
EOF
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–æ–≤ –±—ç–∫–∞–ø–∞
    local backup_files=(
        "postgres_backup_${BACKUP_DATE}.sql.gz"
        "postgres_schema_${BACKUP_DATE}.sql"
        "elasticsearch_${BACKUP_DATE}"
        "configs_${BACKUP_DATE}.tar.gz"
    )
    
    for backup_file in "${backup_files[@]}"; do
        if [ -e "${BACKUP_DIR}/${backup_file}" ]; then
            local size=$(du -sh "${BACKUP_DIR}/${backup_file}" 2>/dev/null | cut -f1 || echo "N/A")
            echo "‚úÖ $backup_file (—Ä–∞–∑–º–µ—Ä: $size)" >> "$report_file"
        else
            echo "‚ùå $backup_file - –ù–ï –°–û–ó–î–ê–ù" >> "$report_file"
        fi
    done
    
    echo "" >> "$report_file"
    echo "–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–ï –î–ò–°–ö–ê:" >> "$report_file"
    df -h "$BACKUP_DIR" >> "$report_file"
    
    echo "" >> "$report_file"
    echo "–û–ë–©–ò–ô –†–ê–ó–ú–ï–† –ë–≠–ö–ê–ü–û–í:" >> "$report_file"
    du -sh "$BACKUP_DIR" >> "$report_file"
    
    log INFO "‚úÖ –û—Ç—á–µ—Ç —Å–æ–∑–¥–∞–Ω: $report_file"
}

# –§—É–Ω–∫—Ü–∏—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è (–∑–∞–≥–ª—É—à–∫–∞ –¥–ª—è –±—É–¥—É—â–µ–≥–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è)
send_notification() {
    local status="$1"
    local message="$2"
    
    # TODO: –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–∞–º–∏ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π (Slack, email, Telegram)
    log INFO "üìß –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ: [$status] $message"
    
    # –ü—Ä–∏–º–µ—Ä –¥–ª—è –±—É–¥—É—â–µ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏:
    # if [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
    #     curl -X POST -H 'Content-type: application/json' \
    #         --data "{\"text\":\"AquaStream Backup [$status]: $message\"}" \
    #         "$SLACK_WEBHOOK_URL"
    # fi
}

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
main() {
    local start_time=$(date +%s)
    local overall_status="SUCCESS"
    local failed_backups=""
    
    log INFO "üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ—Ü–µ–¥—É—Ä—É —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è AquaStream"
    log INFO "üìÖ –î–∞—Ç–∞: $BACKUP_DATE"
    log INFO "üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –±—ç–∫–∞–ø–æ–≤: $BACKUP_DIR"
    log INFO "üïê Retention –ø–µ—Ä–∏–æ–¥: $RETENTION_DAYS –¥–Ω–µ–π"
    echo
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Docker Compose
    if ! docker compose -f "$COMPOSE_FILE" ps >/dev/null 2>&1; then
        log ERROR "‚ùå Docker Compose –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ –ø—Ä–æ–µ–∫—Ç –Ω–µ –∑–∞–ø—É—â–µ–Ω"
        send_notification "FAILED" "Docker Compose –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
        exit 1
    fi
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ
    if ! backup_postgresql; then
        overall_status="PARTIAL"
        failed_backups="$failed_backups PostgreSQL"
    fi
    
    if ! backup_elasticsearch; then
        overall_status="PARTIAL"
        failed_backups="$failed_backups Elasticsearch"
    fi
    
    backup_configs
    backup_docker_volumes
    cleanup_old_backups
    create_backup_report
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    local duration_formatted=$(printf "%02d:%02d:%02d" $((duration/3600)) $((duration%3600/60)) $((duration%60)))
    
    echo
    log INFO "üèÅ –†–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!"
    log INFO "‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: $duration_formatted"
    log INFO "üìä –°—Ç–∞—Ç—É—Å: $overall_status"
    
    if [ "$overall_status" = "SUCCESS" ]; then
        log INFO "‚úÖ –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω—ã"
        send_notification "SUCCESS" "–í—Å–µ –±—ç–∫–∞–ø—ã —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ –∑–∞ $duration_formatted"
    elif [ "$overall_status" = "PARTIAL" ]; then
        log WARN "‚ö†Ô∏è –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å: $failed_backups"
        send_notification "PARTIAL" "–ë—ç–∫–∞–ø –∑–∞–≤–µ—Ä—à–µ–Ω —á–∞—Å—Ç–∏—á–Ω–æ. –ù–µ—É–¥–∞—á–∏: $failed_backups"
    fi
    
    echo
    log INFO "üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è:"
    log INFO "  ‚Ä¢ PostgreSQL: ./restore-volumes.sh --postgres backup_file.sql.gz"
    log INFO "  ‚Ä¢ Elasticsearch: ./restore-volumes.sh --elasticsearch snapshot_dir"
    log INFO "  ‚Ä¢ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: ./restore-volumes.sh --configs configs.tar.gz"
}

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
case "${1:-}" in
    "--help"|"-h")
        echo "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: $0 [–æ–ø—Ü–∏–∏]"
        echo ""
        echo "–û–ø—Ü–∏–∏:"
        echo "  --help, -h                 –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É"
        echo "  --dry-run                  –¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å, —á—Ç–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω–æ"
        echo "  --postgres-only            –¢–æ–ª—å–∫–æ PostgreSQL –±—ç–∫–∞–ø"
        echo "  --elasticsearch-only       –¢–æ–ª—å–∫–æ Elasticsearch –±—ç–∫–∞–ø"
        echo "  --configs-only             –¢–æ–ª—å–∫–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"
        echo ""
        echo "–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:"
        echo "  BACKUP_DIR                 –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –±—ç–∫–∞–ø–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: ./backups)"
        echo "  RETENTION_DAYS             –î–Ω–∏ —Ö—Ä–∞–Ω–µ–Ω–∏—è –±—ç–∫–∞–ø–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 30)"
        echo ""
        exit 0
        ;;
    "--dry-run")
        log INFO "üîç DRY RUN MODE - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è"
        log INFO "üìÇ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –±—ç–∫–∞–ø–æ–≤: $BACKUP_DIR"
        log INFO "üìÖ –ò–º—è –±—ç–∫–∞–ø–∞: backup_${BACKUP_DATE}"
        log INFO "üïê Retention: $RETENTION_DAYS –¥–Ω–µ–π"
        log INFO "üìã –ü–ª–∞–Ω–∏—Ä—É–µ–º—ã–µ –±—ç–∫–∞–ø—ã: PostgreSQL, Elasticsearch, –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, Docker Volumes"
        exit 0
        ;;
    "--postgres-only")
        log INFO "üêò –¢–æ–ª—å–∫–æ PostgreSQL –±—ç–∫–∞–ø"
        backup_postgresql
        exit $?
        ;;
    "--elasticsearch-only")
        log INFO "üîç –¢–æ–ª—å–∫–æ Elasticsearch –±—ç–∫–∞–ø"
        backup_elasticsearch
        exit $?
        ;;
    "--configs-only")
        log INFO "‚öôÔ∏è –¢–æ–ª—å–∫–æ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"
        backup_configs
        exit $?
        ;;
    "")
        # –û–±—ã—á–Ω—ã–π –∑–∞–ø—É—Å–∫ –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        main
        ;;
    *)
        log ERROR "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ–ø—Ü–∏—è: $1"
        log INFO "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ --help –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏"
        exit 1
        ;;
esac