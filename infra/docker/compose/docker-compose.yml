version: "3.9"
name: aquastream

# ---------------------------- anchors ----------------------------
# Health check configurations with improved timeouts and retries
x-hc-fast:   &hc-fast   { interval: 15s, timeout: 5s,  retries: 3,  start_period: 30s }   # For lightweight services
x-hc-normal: &hc-normal { interval: 30s, timeout: 10s, retries: 5,  start_period: 60s }   # For standard services  
x-hc-slow:   &hc-slow   { interval: 45s, timeout: 15s, retries: 8,  start_period: 120s }  # For heavy services (DB, ES)
x-hc-init:   &hc-init   { interval: 5s,  timeout: 10s, retries: 60, start_period: 10s }   # For init containers

x-log: &log-env

  LOGSTASH_HOST: ${LOGSTASH_HOST}
  LOGSTASH_PORT: ${LOGSTASH_PORT}

# ресурсные лимиты (оптимизированы для небольшой нагрузки)
x-limit-micro:  &limit-micro  { cpus: "${CPU_MICRO}",  memory: "${MEM_MICRO}" }
x-limit-tiny:   &limit-tiny   { cpus: "${CPU_TINY}",   memory: "${MEM_TINY}" }
x-limit-small:  &limit-small  { cpus: "${CPU_SMALL}",  memory: "${MEM_SMALL}" }
x-limit-medium: &limit-medium { cpus: "${CPU_MEDIUM}", memory: "${MEM_MEDIUM}" }
x-limit-big:    &limit-big    { cpus: "${CPU_BIG}",    memory: "${MEM_BIG}" }

# ------------------------ networks & volumes ---------------------
networks:
  # Внешняя сеть (Nginx + Frontend)
  public-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.20.0.0/24
    driver_opts:
      com.docker.network.bridge.name: aquastream-public

  # Сеть для API Gateway и микросервисов
  api-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.21.0.0/24
    driver_opts:
      com.docker.network.bridge.name: aquastream-api

  # Сеть для инфраструктурных сервисов
  infra-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.22.0.0/24
    driver_opts:
      com.docker.network.bridge.name: aquastream-infra

  # Сеть для мониторинга
  monitoring-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.23.0.0/24
    driver_opts:
      com.docker.network.bridge.name: aquastream-monitoring

  # Основная сеть (для обратной совместимости)
  aquastream-network:
    driver: bridge

volumes:
  postgres_data:
  elasticsearch_data:
  elasticsearch_certs:
  zookeeper_data:
  kafka_data:
  nginx_logs:
  prometheus_data:
  alertmanager_data:

# ----------------------------- services --------------------------
services:

  # ================ Infrastructure ===============================
  # Nginx Reverse Proxy
  nginx:
    build:
      context: ../../..
      dockerfile: infra/docker/images/Dockerfile.nginx
      args:
        NGINX_TAG: ${NGINX_TAG}
    image: aquastream-nginx:latest
    restart: unless-stopped
    ports:
      - "${NGINX_HTTP_PORT}:80"
      - "${NGINX_HTTPS_PORT}:443"
    volumes:
      - nginx_logs:/var/log/nginx
    networks:
      - public-network
      - api-network
      - monitoring-network
    depends_on:
      api-gateway: { condition: service_healthy }
      frontend: { condition: service_healthy }
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      <<: *hc-normal
    deploy: { resources: { limits: *limit-small } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
      - NET_BIND_SERVICE
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=50m
      - /var/cache/nginx:noexec,nosuid,size=50m
      - /var/run:noexec,nosuid,size=10m

  # SSL Setup for Elasticsearch
  elasticsearch-setup:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_TAG}
    volumes: [ elasticsearch_certs:/usr/share/elasticsearch/config/certs ]
    networks: [ infra-network ]
    user: "0"
    security_opt:
      - no-new-privileges:true
    command: >
      bash -c '
        if [ ! -f config/certs/ca.zip ]; then
          echo "Creating CA";
          bin/elasticsearch-certutil ca --silent --pem -out config/certs/ca.zip;
          unzip config/certs/ca.zip -d config/certs;
        fi;
        if [ ! -f config/certs/certs.zip ]; then
          echo "Creating certs";
          echo -ne \
          "instances:
            - name: elasticsearch
              dns:
                - elasticsearch
                - localhost
              ip:
                - 127.0.0.1
            - name: kibana
              dns:
                - kibana
                - localhost
              ip:
                - 127.0.0.1
          " > config/certs/instances.yml;
          bin/elasticsearch-certutil cert --silent --pem -out config/certs/certs.zip --in config/certs/instances.yml --ca-cert config/certs/ca/ca.crt --ca-key config/certs/ca/ca.key;
          unzip config/certs/certs.zip -d config/certs;
        fi;
        echo "Setting file permissions";
        chown -R root:root config/certs;
        find . -type d -exec chmod 750 \{\} \;;
        find . -type f -exec chmod 640 \{\} \;;
        echo "All done!";
      '
    healthcheck:
      test: ["CMD-SHELL", "[ -f config/certs/elasticsearch/elasticsearch.crt ]"]
      <<: *hc-init

  # Init Elasticsearch users
  elasticsearch-init:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_TAG}
    volumes: [ elasticsearch_certs:/usr/share/elasticsearch/config/certs ]
    networks: [ infra-network ]
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      KIBANA_PASSWORD: ${KIBANA_PASSWORD}
    depends_on:
      elasticsearch: { condition: service_healthy }
    security_opt:
      - no-new-privileges:true
    command: >
      bash -c '
        echo "Waiting for Elasticsearch to be ready...";
        until curl -s --cacert config/certs/ca/ca.crt -u elastic:${ELASTIC_PASSWORD} https://elasticsearch:9200/_cluster/health | grep -q "green\|yellow"; do
          sleep 1;
        done;
        echo "Setting kibana_system password";
        until curl -s --cacert config/certs/ca/ca.crt -u elastic:${ELASTIC_PASSWORD} -X POST https://elasticsearch:9200/_security/user/kibana_system/_password -H "Content-Type: application/json" -d "{\"password\":\"${KIBANA_PASSWORD}\"}" | grep -q "^{}"; do 
          sleep 2; 
        done;
        echo "All done!";
      '
    healthcheck:
      test: ["CMD-SHELL", "curl -s --cacert config/certs/ca/ca.crt -u elastic:${ELASTIC_PASSWORD} https://elasticsearch:9200/_security/user/kibana_system | grep -q 'kibana_system'"]
      <<: *hc-init
  zookeeper:
    image: bitnami/zookeeper:${ZOOKEEPER_TAG}
    restart: unless-stopped
    volumes: [ zookeeper_data:/bitnami/zookeeper ]
    networks: [ infra-network ]
    healthcheck:
      test: ["CMD-SHELL","/opt/bitnami/zookeeper/bin/zkServer.sh status >/dev/null 2>&1 || exit 1"]
      <<: *hc-normal
    deploy: { resources: { limits: *limit-small } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
    user: "1001:1001"

  kafka:
    image: confluentinc/cp-kafka:${KAFKA_TAG}
    ports: ["${KAFKA_HOST_PORT}:19092"]
    environment:
      <<: *log-env
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT_INTERNAL://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:19092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT_INTERNAL://kafka:9092,PLAINTEXT_HOST://localhost:${KAFKA_HOST_PORT}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT_INTERNAL:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    depends_on: { zookeeper: { condition: service_healthy } }
    volumes: [ kafka_data:/var/lib/kafka/data ]
    networks:
      - infra-network
      - api-network
    healthcheck:
      test: ["CMD-SHELL","kafka-topics --bootstrap-server localhost:9092 --list || exit 1"]
      <<: *hc-normal
    deploy: { resources: { limits: *limit-small } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID

  postgres:
    image: postgres:${POSTGRES_TAG}
    restart: unless-stopped
    ports: [ "${POSTGRES_PORT}:5432" ]
    environment:
      POSTGRES_DB: aquastream_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--auth-host=md5"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks: [ infra-network, api-network ]
    healthcheck:
      test: ["CMD-SHELL","pg_isready -U postgres -d aquastream_db"]
      <<: *hc-slow
    deploy: { resources: { limits: *limit-medium } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
    user: "postgres:postgres"
    shm_size: 128mb

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_TAG}
    restart: unless-stopped
    environment:
      discovery.type: single-node
      ES_JAVA_OPTS: -Xms512m -Xmx1024m -XX:+UseG1GC -XX:MaxGCPauseMillis=200
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD}
      xpack.security.enabled: "true"
      xpack.security.http.ssl.enabled: "true"
      xpack.security.http.ssl.key: certs/elasticsearch/elasticsearch.key
      xpack.security.http.ssl.certificate: certs/elasticsearch/elasticsearch.crt
      xpack.security.http.ssl.certificate_authorities: certs/ca/ca.crt
      xpack.security.transport.ssl.enabled: "true"
      xpack.security.transport.ssl.key: certs/elasticsearch/elasticsearch.key
      xpack.security.transport.ssl.certificate: certs/elasticsearch/elasticsearch.crt
      xpack.security.transport.ssl.certificate_authorities: certs/ca/ca.crt
      xpack.security.transport.ssl.verification_mode: certificate
      xpack.license.self_generated.type: basic
    # ports: [ "${ELASTIC_PORT}:9200" ]  # Доступ через Nginx
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
      - elasticsearch_certs:/usr/share/elasticsearch/config/certs
    networks:
      - infra-network
      - monitoring-network
    depends_on:
      elasticsearch-setup: { condition: service_healthy }
    healthcheck:
      test: ["CMD-SHELL","curl -s --cacert config/certs/ca/ca.crt -u elastic:${ELASTIC_PASSWORD} https://localhost:9200/_cluster/health | grep -q '\"status\":\"green\"' || exit 1"]
      <<: *hc-slow
    deploy: { resources: { limits: *limit-big } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536

  logstash:
    image: docker.elastic.co/logstash/logstash:${LOGSTASH_TAG}
    restart: unless-stopped
    volumes:
      - ../../monitoring/logstash/pipeline:/usr/share/logstash/pipeline:ro
      - ../../monitoring/logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
      - elasticsearch_certs:/usr/share/logstash/config/certs:ro
    expose: ["5000", "9600"]  # Внутренние порты, без прямого доступа
    environment:
      LS_JAVA_OPTS: -Xms128m -Xmx128m
      ELASTICSEARCH_HOSTS: https://elasticsearch:9200
      ELASTICSEARCH_USERNAME: elastic
      ELASTICSEARCH_PASSWORD: ${ELASTIC_PASSWORD}
      ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES: /usr/share/logstash/config/certs/ca/ca.crt
    depends_on: { elasticsearch: { condition: service_healthy } }
    networks:
      - infra-network
      - monitoring-network
      - api-network
    healthcheck:
      test: ["CMD-SHELL","curl -s http://localhost:9600 | grep -q '\"status\":\"green\"' || exit 1"]
      <<: *hc-normal
    deploy: { resources: { limits: *limit-small } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
    user: "1000:1000"

  kibana:
    image: docker.elastic.co/kibana/kibana:${KIBANA_TAG}
    restart: unless-stopped
    # ports: [ "${KIBANA_PORT}:5601" ]  # Доступ через Nginx /monitoring/kibana/
    environment:
      SERVERNAME: kibana
      ELASTICSEARCH_HOSTS: https://elasticsearch:9200
      ELASTICSEARCH_USERNAME: kibana_system
      ELASTICSEARCH_PASSWORD: ${KIBANA_PASSWORD}
      ELASTICSEARCH_SSL_CERTIFICATEAUTHORITIES: config/certs/ca/ca.crt
      SERVER_SSL_ENABLED: "true"
      SERVER_SSL_CERTIFICATE: config/certs/kibana/kibana.crt
      SERVER_SSL_KEY: config/certs/kibana/kibana.key
    volumes:
      - elasticsearch_certs:/usr/share/kibana/config/certs:ro
    depends_on:
      elasticsearch: { condition: service_healthy }
      elasticsearch-init: { condition: service_healthy }
    networks: [ monitoring-network ]
    healthcheck:
      test: ["CMD-SHELL","curl -s --cacert config/certs/ca/ca.crt https://localhost:5601/api/status | grep -q '\"state\":\"green\"' || exit 1"]
      <<: *hc-normal
    deploy: { resources: { limits: *limit-small } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
    user: "1000:1000"

  prometheus:
    image: prom/prometheus:${PROM_TAG}
    restart: unless-stopped
    volumes:
      - ../../monitoring/prometheus:/etc/prometheus:ro
      - prometheus_data:/prometheus
    # ports: [ "${PROM_PORT}:9090" ]  # Доступ через Nginx /monitoring/prometheus/
    networks:
      - monitoring-network
      - api-network
    depends_on:
      - alertmanager
    healthcheck:
      test: ["CMD-SHELL","wget --quiet --tries=1 --spider http://localhost:9090/ || exit 1"]
      <<: *hc-normal
    deploy: { resources: { limits: *limit-small } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
    user: "nobody:nobody"
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.path=/prometheus
      - --storage.tsdb.retention.time=15d
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --web.console.templates=/etc/prometheus/consoles
      - --web.enable-lifecycle
      - --web.enable-admin-api
      - --alertmanager.timeout=10s

  # ===== ALERTMANAGER =====
  alertmanager:
    image: prom/alertmanager:${ALERTMANAGER_TAG}
    restart: unless-stopped
    volumes:
      - ../../monitoring/alertmanager:/etc/alertmanager:ro
      - alertmanager_data:/alertmanager
    # ports: [ "${ALERTMANAGER_PORT}:9093" ]  # Доступ через Nginx /monitoring/alertmanager/
    networks:
      - monitoring-network
    healthcheck:
      test: ["CMD-SHELL","wget --quiet --tries=1 --spider http://localhost:9093/ || exit 1"]
      <<: *hc-normal
    deploy: { resources: { limits: *limit-tiny } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
    user: "nobody:nobody"
    command:
      - --config.file=/etc/alertmanager/alertmanager.yml
      - --storage.path=/alertmanager
      - --web.external-url=http://localhost/monitoring/alertmanager/
      - --cluster.listen-address=
      - --log.level=info

  grafana:
    image: grafana/grafana:${GRAFANA_TAG}
    restart: unless-stopped
    volumes:
      - ../../monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - ../../monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    # ports: [ "${GRAFANA_PORT}:3000" ]  # Доступ через Nginx /monitoring/grafana/
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD}
      GF_SECURITY_DISABLE_GRAVATAR: "true"
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_ANALYTICS_REPORTING_ENABLED: "false"
      GF_ANALYTICS_CHECK_FOR_UPDATES: "false"
      GF_SECURITY_COOKIE_SECURE: "true"
      GF_SECURITY_COOKIE_SAMESITE: "strict"
    depends_on:
      - prometheus
      - alertmanager
    networks: [ monitoring-network ]
    healthcheck:
      test: ["CMD-SHELL","wget --quiet --tries=1 --spider http://localhost:3000/ || exit 1"]
      <<: *hc-normal
    deploy: { resources: { limits: *limit-small } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
    user: "472:472"

  # ================ Micro-services ===========================
  user-service:
    build:
      context: ../../..
      dockerfile: infra/docker/images/Dockerfile.backend-user
      args:
        ECLIPSE_TEMURIN_JDK_TAG: ${ECLIPSE_TEMURIN_JDK_TAG}
        ECLIPSE_TEMURIN_JRE_TAG: ${ECLIPSE_TEMURIN_JRE_TAG}
    image: aquastream-user:latest
    restart: unless-stopped
    expose: ['8081']
    environment:
      <<: *log-env
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/aquastream_db
      SPRING_DATASOURCE_USERNAME: postgres
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    depends_on:
      postgres:  { condition: service_healthy }
      kafka:     { condition: service_healthy }
      logstash:  { condition: service_healthy }
    networks: [ api-network ]
    healthcheck:
      test: ['CMD','curl','-fs','http://localhost:8081/actuator/health']
      <<: *hc-fast
    deploy: { resources: { limits: *limit-tiny } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    tmpfs:
      - /tmp:noexec,nosuid,size=50m
    read_only: true

  crew-service:
    build:
      context: ../../..
      dockerfile: infra/docker/images/Dockerfile.backend-crew
      args:
        ALPINE_TAG: ${ALPINE_TAG}
    image: aquastream-crew:latest
    restart: unless-stopped
    expose: ['8083']
    environment:
      <<: *log-env
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/aquastream_db
      SPRING_DATASOURCE_USERNAME: postgres
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    depends_on:
      postgres:  { condition: service_healthy }
      kafka:     { condition: service_healthy }
      logstash:  { condition: service_healthy }
    networks: [ api-network ]
    healthcheck:
      test: ['CMD','curl','-fs','http://localhost:8083/actuator/health']
      <<: *hc-fast
    deploy: { resources: { limits: *limit-micro } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    tmpfs:
      - /tmp:noexec,nosuid,size=50m
    read_only: true

  event-service:
    build:
      context: ../../..
      dockerfile: infra/docker/images/Dockerfile.backend-event
      args:
        ALPINE_TAG: ${ALPINE_TAG}
    image: aquastream-event:latest
    restart: unless-stopped
    expose: ['8082']
    environment:
      <<: *log-env
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    depends_on:
      kafka:     { condition: service_healthy }
      logstash:  { condition: service_healthy }
    networks: [ api-network ]
    healthcheck:
      test: ['CMD','curl','-fs','http://localhost:8082/actuator/health']
      <<: *hc-fast
    deploy: { resources: { limits: *limit-micro } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    tmpfs:
      - /tmp:noexec,nosuid,size=50m
    read_only: true

  notification-service:
    build:
      context: ../../..
      dockerfile: infra/docker/images/Dockerfile.backend-notification
      args:
        ALPINE_TAG: ${ALPINE_TAG}
    image: aquastream-notification:latest
    restart: unless-stopped
    expose: ['8084']
    environment:
      <<: *log-env
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/aquastream_db
      SPRING_DATASOURCE_USERNAME: postgres
      SPRING_DATASOURCE_PASSWORD: ${POSTGRES_PASSWORD}
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
    depends_on:
      postgres:  { condition: service_healthy }
      kafka:     { condition: service_healthy }
      logstash:  { condition: service_healthy }
    networks: [ api-network ]
    healthcheck:
      test: ['CMD','curl','-fs','http://localhost:8084/actuator/health']
      <<: *hc-fast
    deploy: { resources: { limits: *limit-micro } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    tmpfs:
      - /tmp:noexec,nosuid,size=50m
    read_only: true

  # ============== Gateway & Frontend =========================
  api-gateway:
    build:
      context: ../../..
      dockerfile: infra/docker/images/Dockerfile.backend-gateway
      args:
        ECLIPSE_TEMURIN_JDK_TAG: ${ECLIPSE_TEMURIN_JDK_TAG}
        ECLIPSE_TEMURIN_JRE_TAG: ${ECLIPSE_TEMURIN_JRE_TAG}
    image: aquastream-api:latest
    restart: unless-stopped
    environment: *log-env
    expose: ["8080"]  # Доступ через Nginx /api/
    depends_on:
      user-service:         { condition: service_healthy }
      crew-service:         { condition: service_healthy }
      event-service:        { condition: service_healthy }
      notification-service: { condition: service_healthy }
      logstash:             { condition: service_healthy }
    networks: [ api-network ]
    healthcheck:
      test: ['CMD','curl','-fs','http://localhost:8080/actuator/health']
      <<: *hc-fast
    deploy: { resources: { limits: *limit-tiny } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    tmpfs:
      - /tmp:noexec,nosuid,size=50m
    read_only: true

  frontend:
    build:
      context: ../../..
      dockerfile: infra/docker/images/Dockerfile.frontend
      args:
        NODE_TAG: ${NODE_TAG}
        NGINX_TAG: ${NGINX_TAG}
    image: aquastream-frontend:latest
    restart: unless-stopped
    expose: ["80"]  # Доступ через Nginx /
    depends_on: { api-gateway: { condition: service_healthy } }
    networks: [ public-network ]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      <<: *hc-fast
    deploy: { resources: { limits: *limit-micro } }
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - DAC_OVERRIDE
      - SETGID
      - SETUID
    user: "nginx:nginx"
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=10m
      - /var/cache/nginx:noexec,nosuid,size=10m
      - /var/run:noexec,nosuid,size=5m