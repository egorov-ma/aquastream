# Стратегия резервного копирования AquaStream

## Обзор

Стратегия резервного копирования AquaStream обеспечивает комплексную защиту данных с автоматизированным созданием бэкапов, интеллектуальным управлением жизненным циклом и быстрым восстановлением.

## Компоненты для резервного копирования

### Критичные данные (Priority 1)
- **PostgreSQL** - основная база данных приложений
- **Elasticsearch данные** - индексы логов и поиска
- **Конфигурационные файлы** - Docker Compose, переменные окружения, скрипты

### Важные данные (Priority 2)
- **Kafka данные** - очереди сообщений
- **ZooKeeper данные** - конфигурация кластера
- **SSL сертификаты** - Elasticsearch TLS сертификаты
- **Nginx логи** - access и error логи

### Дополнительные данные (Priority 3)
- **Monitoring данные** - метрики Prometheus, дашборды Grafana
- **Логи приложений** - структурированные логи сервисов

## Типы резервного копирования

### 1. Полный бэкап (Full Backup)
- **Частота**: Ежедневно в 2:00 AM
- **Включает**: Все компоненты Priority 1 и 2
- **Время выполнения**: ~15-30 минут
- **Размер**: ~1-5 GB (зависит от объема данных)

### 2. Инкрементальный бэкап (Incremental)
- **PostgreSQL**: Каждые 6 часов
- **Включает**: Только изменения данных
- **Время выполнения**: ~2-5 минут
- **Размер**: ~10-100 MB

### 3. Еженедельный архив (Weekly Archive)
- **Частота**: Воскресенье в 1:00 AM
- **Включает**: Полный бэкап + архивирование
- **Хранение**: 12 недель (3 месяца)
- **Сжатие**: tar.gz для экономии места

### 4. Конфигурационный бэкап (Config Backup)
- **Частота**: При каждом полном бэкапе
- **Включает**: Все файлы конфигурации и скрипты
- **Размер**: ~1-10 MB

## Схема хранения бэкапов

```
/backups/aquastream/
├── postgres_backup_20240802_020000.sql.gz
├── postgres_schema_20240802_020000.sql
├── elasticsearch_20240802_020000/
│   ├── indices/
│   ├── meta-global/
│   └── snapshot-metadata
├── configs_20240802_020000.tar.gz
├── volumes_20240802_020000/
│   ├── postgres_data.tar.gz
│   ├── elasticsearch_data.tar.gz
│   ├── kafka_data.tar.gz
│   └── zookeeper_data.tar.gz
├── weekly/
│   └── weekly_backup_2024_week_31.tar.gz
└── backup_report_20240802_020000.txt
```

## Политики хранения (Retention)

### Ежедневные бэкапы
- **Хранение**: 30 дней
- **Автоочистка**: Ежемесячно 1 числа в 3:00 AM
- **Критерий**: mtime > 30 дней

### Еженедельные архивы
- **Хранение**: 12 недель (3 месяца)
- **Автоочистка**: При создании нового архива
- **Критерий**: mtime > 84 дня

### PostgreSQL инкрементальные
- **Хранение**: 7 дней
- **Автоочистка**: Ежедневно
- **Критерий**: mtime > 7 дней

### Логи и отчеты
- **Хранение**: 90 дней
- **Размер**: Ограничение по размеру 1GB
- **Автоочистка**: По размеру и времени

## Автоматизация с Cron

### Настройка cron задач

```bash
# Редактируем crontab
crontab -e

# Добавляем задачи
0 2 * * * /path/to/aquastream/infra/scripts/backup-cron-example.sh full
0 */6 * * * /path/to/aquastream/infra/scripts/backup-cron-example.sh postgres
0 1 * * 0 /path/to/aquastream/infra/scripts/backup-cron-example.sh weekly
0 3 1 * * /path/to/aquastream/infra/scripts/backup-cron-example.sh cleanup
```

### Мониторинг задач

```bash
# Просмотр логов cron
tail -f /var/log/cron

# Проверка статуса последних бэкапов
./infra/scripts/backup-cron-example.sh health

# Список доступных бэкапов
./infra/scripts/restore-volumes.sh --list
```

## Процедуры восстановления

### 1. Восстановление PostgreSQL

```bash
# Полное восстановление из дампа
./infra/scripts/restore-volumes.sh --postgres /backups/postgres_backup_20240802_020000.sql.gz

# Восстановление только схемы
./infra/scripts/restore-volumes.sh --postgres /backups/postgres_schema_20240802_020000.sql
```

### 2. Восстановление Elasticsearch

```bash
# Восстановление из snapshot
./infra/scripts/restore-volumes.sh --elasticsearch /backups/elasticsearch_20240802_020000/

# Проверка восстановленных индексов
curl -k -u elastic:password https://localhost:9200/_cat/indices?v
```

### 3. Восстановление конфигураций

```bash
# Восстановление конфигурационных файлов
./infra/scripts/restore-volumes.sh --configs /backups/configs_20240802_020000.tar.gz

# Перезапуск сервисов после восстановления конфигураций
./run.sh stop && ./run.sh start
```

### 4. Восстановление Docker volumes

```bash
# Восстановление отдельного volume
./infra/scripts/restore-volumes.sh --volume postgres_data /backups/volumes_20240802_020000/postgres_data.tar.gz

# Восстановление всех volumes из еженедельного архива
tar -xzf /backups/weekly_backup_2024_week_31.tar.gz
./infra/scripts/restore-volumes.sh --volume postgres_data ./volumes_20240802_020000/postgres_data.tar.gz
```

## RTO/RPO целевые показатели

### Recovery Time Objective (RTO)
- **PostgreSQL**: 15 минут (включая проверку целостности)
- **Elasticsearch**: 30 минут (включая переиндексацию)
- **Конфигурации**: 5 минут
- **Полное восстановление системы**: 60 минут

### Recovery Point Objective (RPO)
- **PostgreSQL**: 6 часов (инкрементальные бэкапы)
- **Elasticsearch**: 24 часа (ежедневные snapshots)
- **Конфигурации**: 24 часа
- **Критичные данные**: Максимум 6 часов потерь

## Тестирование восстановления

### Ежемесячное тестирование

```bash
# 1. Создаем тестовую среду
export BACKUP_DIR="/backups/aquastream"
export TEST_ENV="test"

# 2. Восстанавливаем последние бэкапы в тестовую среду
./infra/scripts/test-restore.sh --full-test

# 3. Проверяем целостность данных
./infra/scripts/validate-backup.sh --check-integrity

# 4. Документируем результаты тестирования
```

### Автоматические проверки

- **Проверка целостности PostgreSQL дампов**: pg_dump --verbose
- **Валидация Elasticsearch snapshots**: GET /_snapshot/repo/_verify
- **Проверка размеров бэкапов**: сравнение с предыдущими периодами
- **Тест доступности сервисов**: health checks после восстановления

## Мониторинг и уведомления

### Metrics для отслеживания

1. **Размер бэкапов по времени**
2. **Время выполнения бэкапов**
3. **Успешность операций бэкапа**
4. **Использование дискового пространства**
5. **Возраст последнего успешного бэкапа**

### Алерты

- **Неудачный бэкап**: немедленное уведомление
- **Размер бэкапа аномально отличается**: предупреждение
- **Диск заполнен > 85%**: критический алерт
- **Нет бэкапа > 25 часов**: предупреждение
- **Ошибка валидации бэкапа**: критический алерт

### Каналы уведомлений

- **Email**: admin@company.com
- **Slack**: #ops-alerts канал
- **SMS**: критические алерты (опционально)
- **Dashboard**: Grafana мониторинг

## Безопасность бэкапов

### Шифрование

```bash
# Шифрование бэкапов с GPG
gpg --symmetric --cipher-algo AES256 backup_file.tar.gz

# Расшифровка
gpg --decrypt backup_file.tar.gz.gpg > backup_file.tar.gz
```

### Контроль доступа

- **Права доступа**: 600 (только владелец)
- **Пользователь**: backup (специальный системный пользователь)
- **Сетевое хранилище**: VPN или private network
- **Аудит доступа**: логирование всех операций с бэкапами

### Географическое распределение

- **Локальные бэкапы**: основной сервер
- **Удаленные бэкапы**: облачное хранилище или другой ЦОД
- **Синхронизация**: rsync или cloud sync каждые 24 часа

## Disaster Recovery процедуры

### Сценарий 1: Отказ базы данных

1. **Остановить приложения**
2. **Восстановить PostgreSQL из последнего дампа**
3. **Применить инкрементальные изменения если доступны**
4. **Запустить приложения и проверить работоспособность**

### Сценарий 2: Полный отказ системы

1. **Подготовить новую среду**
2. **Восстановить конфигурации**
3. **Восстановить все данные из еженедельного архива**
4. **Применить ежедневные бэкапы**
5. **Тестирование и переключение трафика**

### Сценарий 3: Повреждение данных

1. **Определить момент повреждения**
2. **Выбрать ближайший валидный бэкап**
3. **Восстановить данные на определенную дату**
4. **Вручную восстановить критичные изменения**

## Требования к инфраструктуре

### Дисковое пространство

- **Минимум**: 50GB для 30-дневного retention
- **Рекомендуется**: 200GB для комфортной работы
- **Мониторинг**: алерт при заполнении > 80%

### Сетевые требования

- **Пропускная способность**: минимум 100 Mbps для удаленных бэкапов
- **Latency**: < 50ms для локальных операций
- **Доступность**: 99.5% uptime для storage

### Вычислительные ресурсы

- **CPU**: 2 ядра для параллельного сжатия
- **RAM**: 4GB для больших операций бэкапа
- **I/O**: SSD storage для быстрых операций

## Compliance и аудит

### Соответствие требованиям

- **Retention policies**: согласно корпоративным политикам
- **Encryption**: данные шифруются в покое и в движении
- **Access control**: минимальные привилегии
- **Audit trail**: логирование всех операций

### Документирование

- **Backup reports**: автоматические отчеты о каждом бэкапе
- **Recovery tests**: ежемесячные тесты восстановления
- **Change log**: документирование изменений в процедурах
- **Incident reports**: анализ проблем и улучшения

## Планы улучшения

### Краткосрочные (1-3 месяца)

- [ ] Интеграция с облачным хранилищем (AWS S3/Azure Blob)
- [ ] Автоматическое тестирование целостности бэкапов
- [ ] Dashboard для мониторинга бэкапов в Grafana
- [ ] Point-in-time recovery для PostgreSQL

### Среднесрочные (3-6 месяцев)

- [ ] Cross-region репликация бэкапов
- [ ] Автоматическое масштабирование retention политик
- [ ] Integration с корпоративной системой мониторинга
- [ ] Disaster recovery automation

### Долгосрочные (6-12 месяцев)

- [ ] Continuous Data Protection (CDP)
- [ ] AI-based anomaly detection для бэкапов
- [ ] Multi-cloud backup strategy
- [ ] Compliance automation (GDPR, SOX, etc.)